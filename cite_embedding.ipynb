{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "174d1c51-29b3-457b-8c05-0b95f7c5ef3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Source context with [CITE] and [REF]:\n",
      "A '''mall''' or '''shopping center''' is a large <CITE> that is full of many smaller [[shop]]s. <REF>\n",
      "\n",
      "Target page with [REF]:\n",
      "A building is a human-made structure with a roof and walls. \n",
      "        Buildings come in many sizes and shapes and have been adapted to a wide range of functions.\n",
      "        They can be used for housing, c... <REF>\n",
      "\n",
      "Performing example training step...\n",
      "####################\n",
      "similarity =  tensor([[14.2422]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<DivBackward0>) , labels =  tensor([0], device='cuda:0')\n",
      "Training loss: 0.0000\n",
      "\n",
      "Computing similarity...\n",
      "Similarity score: 14.2422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_704312/4229892726.py:242: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "/tmp/ipykernel_704312/4229892726.py:253: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "class AutoregressiveCitationMatcher(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"gpt2\",\n",
    "        max_length: int = 512,\n",
    "        cite_token: str = \"<CITE>\",\n",
    "        ref_token: str = \"<REF>\",\n",
    "        device: torch.device = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Set device\n",
    "        self.device = device if device is not None else torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        # Add special tokens for citation and reference\n",
    "        special_tokens = {\n",
    "            'additional_special_tokens': [cite_token, ref_token]\n",
    "        }\n",
    "        self.tokenizer.add_special_tokens(special_tokens)\n",
    "        \n",
    "        # For GPT models, we might need to set pad token if it's not set\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Initialize encoder for both source and target texts\n",
    "        # We use the same model for both since autoregressive models maintain context\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name).to(self.device)\n",
    "        \n",
    "        # Resize token embeddings\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        \n",
    "        self.cite_token = cite_token\n",
    "        self.ref_token = ref_token\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        hidden_size = self.model.config.hidden_size\n",
    "        # We'll use these to project the [REF] embeddings from both source and target\n",
    "        self.source_projector = nn.Linear(hidden_size, hidden_size).to(self.device)\n",
    "        self.target_projector = nn.Linear(hidden_size, hidden_size).to(self.device)\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "    def prepare_source_context(\n",
    "        self,\n",
    "        text: str,\n",
    "        target_citation: str,\n",
    "        window_size: int = 100\n",
    "    ) -> str:\n",
    "        \"\"\"Prepare source context with citation and reference tokens.\"\"\"\n",
    "        citation_pattern = re.escape(f\"[[{target_citation}]]\")\n",
    "        # Add both [CITE] and [REF] tokens\n",
    "        modified_text = re.sub(citation_pattern, f\"{self.cite_token}\", text)\n",
    "        modified_text = f\"{modified_text} {self.ref_token}\"\n",
    "        \n",
    "        cite_pos = modified_text.find(self.cite_token)\n",
    "        if cite_pos == -1:\n",
    "            raise ValueError(\"Citation token not found in text\")\n",
    "            \n",
    "        # Include full context up to the [REF] token\n",
    "        start = max(0, cite_pos - window_size)\n",
    "        return modified_text[start:]\n",
    "\n",
    "    def prepare_target_page(\n",
    "        self,\n",
    "        page_content: str,\n",
    "        max_summary_length: int = 200\n",
    "    ) -> str:\n",
    "        \"\"\"Prepare target page with reference token.\"\"\"\n",
    "        # Take first paragraph as summary\n",
    "        first_para = page_content.split('\\n\\n')[0].strip()\n",
    "        if len(first_para) > max_summary_length:\n",
    "            first_para = first_para[:max_summary_length] + \"...\"\n",
    "            \n",
    "        return f\"{first_para} {self.ref_token}\"\n",
    "\n",
    "    def get_token_embedding(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        input_ids: torch.Tensor,\n",
    "        token_id: int\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Extract embedding for specific token.\"\"\"\n",
    "        # Get token positions (batch_size, num_occurrences)\n",
    "        token_positions = (input_ids == token_id).nonzero()\n",
    "        \n",
    "        if len(token_positions) == 0:\n",
    "            raise ValueError(f\"Token id {token_id} not found in sequence\")\n",
    "        \n",
    "        # Extract embeddings at token positions\n",
    "        token_embeddings = hidden_states[\n",
    "            token_positions[:, 0],\n",
    "            token_positions[:, 1]\n",
    "        ]\n",
    "        \n",
    "        # If multiple occurrences, raise an error\n",
    "        if len(token_positions) > 1:\n",
    "            raise ValueError(f\"There should only be one occurance of REF token\")\n",
    "            \n",
    "        return token_embeddings\n",
    "\n",
    "    def encode_text(\n",
    "        self,\n",
    "        text: str,\n",
    "        is_source: bool = True\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode text and extract reference token embedding.\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Get hidden states from the model\n",
    "        outputs = self.model(\n",
    "            **inputs,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        # Get [REF] token embedding from the last hidden state\n",
    "        ref_token_id = self.tokenizer.convert_tokens_to_ids(self.ref_token)\n",
    "        ref_embeddings = self.get_token_embedding(\n",
    "            outputs.hidden_states[-1],\n",
    "            inputs['input_ids'],\n",
    "            ref_token_id\n",
    "        )\n",
    "        return ref_embeddings\n",
    "        \n",
    "        # Project the embeddings based on whether it's source or target\n",
    "    \n",
    "        # if is_source:\n",
    "        #     return self.source_projector(ref_embeddings)\n",
    "        # else:\n",
    "        #     return self.target_projector(ref_embeddings)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        source_contexts: List[str],\n",
    "        target_pages: List[str],\n",
    "        temperature: float = 0.07\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Compute similarity between source and target [REF] embeddings.\"\"\"\n",
    "        # Encode all contexts and references\n",
    "        source_embeddings = []\n",
    "        target_embeddings = []\n",
    "        \n",
    "        for context in source_contexts:\n",
    "            source_emb = self.encode_text(context, is_source=True)\n",
    "            source_embeddings.append(source_emb)\n",
    "            \n",
    "        for page in target_pages:\n",
    "            target_emb = self.encode_text(page, is_source=False)\n",
    "            target_embeddings.append(target_emb)\n",
    "        \n",
    "        # Stack embeddings\n",
    "        source_embeddings = torch.cat(source_embeddings, dim=0)\n",
    "        target_embeddings = torch.cat(target_embeddings, dim=0)\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        source_embeddings = nn.functional.normalize(source_embeddings, dim=-1)\n",
    "        target_embeddings = nn.functional.normalize(target_embeddings, dim=-1)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarity = torch.matmul(\n",
    "            source_embeddings,\n",
    "            target_embeddings.transpose(0, 1)\n",
    "        ) / temperature\n",
    "        \n",
    "        return similarity\n",
    "\n",
    "    def train_step(\n",
    "        self,\n",
    "        source_contexts: List[str],\n",
    "        target_pages: List[str],\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        temperature: float = 0.07\n",
    "    ) -> float:\n",
    "        \"\"\"Perform one training step.\"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        similarity = self(source_contexts, target_pages, temperature)\n",
    "        \n",
    "        # The diagonal elements should be the positive pairs\n",
    "        labels = torch.arange(len(source_contexts)).to(self.device)\n",
    "        # print('#'*20)\n",
    "        # print('similarity = ', similarity, ', labels = ', labels)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = nn.CrossEntropyLoss()(similarity, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "\n",
    "def main():\n",
    "    # Example data\n",
    "    source_text = \"\"\"A '''mall''' or '''shopping center''' is a large [[building]] that is full of many smaller [[shop]]s.\"\"\"\n",
    "    \n",
    "    target_pages = {\n",
    "        \"building\": \"\"\"A building is a human-made structure with a roof and walls. \n",
    "        Buildings come in many sizes and shapes and have been adapted to a wide range of functions.\n",
    "        They can be used for housing, commercial, educational, or industrial activities.\"\"\",\n",
    "        \n",
    "        \"shop\": \"\"\"A shop, also known as a store or retail establishment, is a business premises \n",
    "        that sells goods directly to customers. Shops can be independent small businesses or \n",
    "        part of larger retail chains.\"\"\"\n",
    "    }\n",
    "    \n",
    "    # Initialize model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = AutoregressiveCitationMatcher(device=device)\n",
    "    \n",
    "    # Prepare inputs for first citation\n",
    "    source_context = model.prepare_source_context(source_text, \"building\")\n",
    "    target_content = model.prepare_target_page(target_pages[\"building\"])\n",
    "    \n",
    "    print(\"Source context with [CITE] and [REF]:\")\n",
    "    print(source_context)\n",
    "    print(\"\\nTarget page with [REF]:\")\n",
    "    print(target_content)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    \n",
    "    # Example training step\n",
    "    print(\"\\nPerforming example training step...\")\n",
    "    with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "        loss = model.train_step(\n",
    "            [source_context],\n",
    "            [target_content],\n",
    "            optimizer\n",
    "        )\n",
    "    print(f\"Training loss: {loss:.4f}\")\n",
    "    \n",
    "    # Compute similarity\n",
    "    print(\"\\nComputing similarity...\")\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            similarity = model([source_context], [target_content])\n",
    "    print(f\"Similarity score: {similarity[0][0].item():.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e10aa78-f31a-4eb6-91eb-4e90da2037b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_positions =  tensor([[0, 3],\n",
      "        [0, 5],\n",
      "        [1, 7]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3096,  0.5539,  0.1889,  ...,  1.3846,  0.5829,  0.5157],\n",
       "        [-0.0750, -0.3833, -1.4829,  ..., -0.4143,  1.0510, -0.6311],\n",
       "        [-0.5740,  0.5425,  0.4611,  ...,  0.3298,  0.3939, -0.5214]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = torch.randn(2, 10, 768)  # [batch_size, seq_len, hidden_size]\n",
    "input_ids = torch.tensor([\n",
    "    [1, 2, 3, 100, 5, 100, 7, 8, 9, 10],  # batch 1, token_id 100 appears twice\n",
    "    [1, 2, 3, 4, 5, 6, 7, 100, 9, 10]     # batch 2, token_id 100 appears once\n",
    "])\n",
    "token_id = 100\n",
    "token_positions = (input_ids == token_id).nonzero()\n",
    "print('token_positions = ', token_positions)\n",
    "\n",
    "token_embeddings = hidden_states[\n",
    "    token_positions[:, 0],  # batch indices\n",
    "    token_positions[:, 1]   # sequence positions\n",
    "]\n",
    "\n",
    "token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64717a5c-3b9b-41e8-81a0-ace988f60d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amir/miniconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting training loop...\n",
      "Epoch 1, Step 1/10, Loss: 1.3787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1707755/2217057553.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2/10, Loss: 1.3484\n",
      "Epoch 1, Step 3/10, Loss: 1.2130\n",
      "Epoch 1, Step 4/10, Loss: 0.8815\n",
      "Epoch 1, Step 5/10, Loss: 0.8069\n",
      "Epoch 1, Step 6/10, Loss: 0.7612\n",
      "Epoch 1, Step 7/10, Loss: 0.6135\n",
      "Epoch 1, Step 8/10, Loss: 8.0613\n",
      "Epoch 1, Step 9/10, Loss: 4.4313\n",
      "Epoch 1, Step 10/10, Loss: 4.6977\n",
      "Epoch 1 complete. Average loss: 2.4193\n",
      "Epoch 2, Step 1/10, Loss: 3.4214\n",
      "Epoch 2, Step 2/10, Loss: 3.4023\n",
      "Epoch 2, Step 3/10, Loss: 1.8708\n",
      "Epoch 2, Step 4/10, Loss: 0.7561\n",
      "Epoch 2, Step 5/10, Loss: 0.7629\n",
      "Epoch 2, Step 6/10, Loss: 0.7691\n",
      "Epoch 2, Step 7/10, Loss: 0.7720\n",
      "Epoch 2, Step 8/10, Loss: 0.7801\n",
      "Epoch 2, Step 9/10, Loss: 0.7840\n",
      "Epoch 2, Step 10/10, Loss: 0.7914\n",
      "Epoch 2 complete. Average loss: 1.4110\n",
      "Epoch 3, Step 1/10, Loss: 0.8025\n",
      "Epoch 3, Step 2/10, Loss: 0.8111\n",
      "Epoch 3, Step 3/10, Loss: 0.8156\n",
      "Epoch 3, Step 4/10, Loss: 0.8202\n",
      "Epoch 3, Step 5/10, Loss: 0.8271\n",
      "Epoch 3, Step 6/10, Loss: 0.8326\n",
      "Epoch 3, Step 7/10, Loss: 0.8344\n",
      "Epoch 3, Step 8/10, Loss: 0.8377\n",
      "Epoch 3, Step 9/10, Loss: 0.8377\n",
      "Epoch 3, Step 10/10, Loss: 0.8394\n",
      "Epoch 3 complete. Average loss: 0.8258\n",
      "\n",
      "Testing model with a sample prediction...\n",
      "Similarity score: 14.2266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1707755/2217057553.py:415: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "class AutoregressiveCitationMatcher(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"gpt2\",\n",
    "        max_length: int = 512,\n",
    "        cite_token: str = \"<CITE>\",\n",
    "        ref_token: str = \"<REF>\",\n",
    "        device: torch.device = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Set device\n",
    "        self.device = device if device is not None else torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        # Add special tokens for citation and reference\n",
    "        special_tokens = {\n",
    "            'additional_special_tokens': [cite_token, ref_token]\n",
    "        }\n",
    "        self.tokenizer.add_special_tokens(special_tokens)\n",
    "        \n",
    "        # For GPT models, we might need to set pad token if it's not set\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Initialize encoder for both source and target texts\n",
    "        # We use the same model for both since autoregressive models maintain context\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name).to(self.device)\n",
    "        \n",
    "        # Resize token embeddings\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        \n",
    "        self.cite_token = cite_token\n",
    "        self.ref_token = ref_token\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        hidden_size = self.model.config.hidden_size\n",
    "        # We'll use these to project the [REF] embeddings from both source and target\n",
    "        self.source_projector = nn.Linear(hidden_size, hidden_size).to(self.device)\n",
    "        self.target_projector = nn.Linear(hidden_size, hidden_size).to(self.device)\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "    def prepare_source_context(\n",
    "        self,\n",
    "        text: str,\n",
    "        target_citation: str,\n",
    "        window_size: int = 100\n",
    "    ) -> str:\n",
    "        \"\"\"Prepare source context with citation and reference tokens.\"\"\"\n",
    "        citation_pattern = re.escape(f\"[[{target_citation}]]\")\n",
    "        # Add both [CITE] and [REF] tokens\n",
    "        modified_text = re.sub(citation_pattern, f\"{self.cite_token}\", text)\n",
    "        modified_text = f\"{modified_text} {self.ref_token}\"\n",
    "        \n",
    "        cite_pos = modified_text.find(self.cite_token)\n",
    "        if cite_pos == -1:\n",
    "            raise ValueError(\"Citation token not found in text\")\n",
    "            \n",
    "        # Include full context up to the [REF] token\n",
    "        start = max(0, cite_pos - window_size)\n",
    "        return modified_text[start:]\n",
    "\n",
    "    def prepare_target_page(\n",
    "        self,\n",
    "        page_content: str,\n",
    "        max_summary_length: int = 200\n",
    "    ) -> str:\n",
    "        \"\"\"Prepare target page with reference token.\"\"\"\n",
    "        # Take first paragraph as summary\n",
    "        first_para = page_content.split('\\n\\n')[0].strip()\n",
    "        if len(first_para) > max_summary_length:\n",
    "            first_para = first_para[:max_summary_length] + \"...\"\n",
    "            \n",
    "        return f\"{first_para} {self.ref_token}\"\n",
    "\n",
    "    def get_token_embedding(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        input_ids: torch.Tensor,\n",
    "        token_id: int\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Extract embedding for specific token.\"\"\"\n",
    "        # Get token positions (batch_size, num_occurrences)\n",
    "        token_positions = (input_ids == token_id).nonzero()\n",
    "        \n",
    "        if len(token_positions) == 0:\n",
    "            raise ValueError(f\"Token id {token_id} not found in sequence\")\n",
    "        \n",
    "        # Extract embeddings at token positions\n",
    "        token_embeddings = hidden_states[\n",
    "            token_positions[:, 0],\n",
    "            token_positions[:, 1]\n",
    "        ]\n",
    "        \n",
    "        # If multiple occurrences, raise an error\n",
    "        if len(token_positions) > 1:\n",
    "            raise ValueError(f\"There should only be one occurance of REF token\")\n",
    "            \n",
    "        return token_embeddings\n",
    "\n",
    "    def encode_text(\n",
    "        self,\n",
    "        text: str,\n",
    "        is_source: bool = True\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode text and extract reference token embedding.\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Get hidden states from the model\n",
    "        outputs = self.model(\n",
    "            **inputs,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        # Get [REF] token embedding from the last hidden state\n",
    "        ref_token_id = self.tokenizer.convert_tokens_to_ids(self.ref_token)\n",
    "        ref_embeddings = self.get_token_embedding(\n",
    "            outputs.hidden_states[-1],\n",
    "            inputs['input_ids'],\n",
    "            ref_token_id\n",
    "        )\n",
    "        return ref_embeddings\n",
    "        \n",
    "        # Project the embeddings based on whether it's source or target\n",
    "    \n",
    "        # if is_source:\n",
    "        #     return self.source_projector(ref_embeddings)\n",
    "        # else:\n",
    "        #     return self.target_projector(ref_embeddings)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        source_contexts: List[str],\n",
    "        target_pages: List[str],\n",
    "        temperature: float = 0.07\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Compute similarity between source and target [REF] embeddings.\"\"\"\n",
    "        # Encode all contexts and references\n",
    "        source_embeddings = []\n",
    "        target_embeddings = []\n",
    "        \n",
    "        for context in source_contexts:\n",
    "            source_emb = self.encode_text(context, is_source=True)\n",
    "            source_embeddings.append(source_emb)\n",
    "            \n",
    "        for page in target_pages:\n",
    "            target_emb = self.encode_text(page, is_source=False)\n",
    "            target_embeddings.append(target_emb)\n",
    "        \n",
    "        # Stack embeddings\n",
    "        source_embeddings = torch.cat(source_embeddings, dim=0)\n",
    "        target_embeddings = torch.cat(target_embeddings, dim=0)\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        source_embeddings = nn.functional.normalize(source_embeddings, dim=-1)\n",
    "        target_embeddings = nn.functional.normalize(target_embeddings, dim=-1)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarity = torch.matmul(\n",
    "            source_embeddings,\n",
    "            target_embeddings.transpose(0, 1)\n",
    "        ) / temperature\n",
    "        \n",
    "        return similarity\n",
    "\n",
    "    def train_step(\n",
    "        self,\n",
    "        source_contexts: List[str],\n",
    "        target_pages: List[str],\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        temperature: float = 0.07\n",
    "    ) -> float:\n",
    "        \"\"\"Perform one training step.\"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        similarity = self(source_contexts, target_pages, temperature)\n",
    "        \n",
    "        # The diagonal elements should be the positive pairs\n",
    "        labels = torch.arange(len(source_contexts)).to(self.device)\n",
    "        # print('#'*20)\n",
    "        # print('similarity = ', similarity, ', labels = ', labels)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = nn.CrossEntropyLoss()(similarity, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "\n",
    "# Dictionary of source pages (articles) with their content\n",
    "source_pages = {\n",
    "    \"Machine_Learning\": \"\"\"'''Machine learning''' is a subfield of [[artificial intelligence]] that focuses on developing systems that can learn from [[data]].\n",
    "    Traditional machine learning approaches include [[supervised learning]], [[unsupervised learning]], and [[reinforcement learning]].\n",
    "    Modern applications often use [[deep learning]] architectures trained on large datasets.\n",
    "    The field has seen significant advances since the development of [[neural network|neural networks]].\"\"\",\n",
    "    \n",
    "    \"Climate_Change\": \"\"\"'''Climate change''' refers to long-term alterations in [[Earth]]'s climate systems.\n",
    "    Major factors include [[greenhouse gas|greenhouse gases]] and [[carbon dioxide]] emissions.\n",
    "    Scientists study [[glacier|glaciers]] and [[ice sheet|ice sheets]] to understand historical climate patterns.\n",
    "    [[Renewable energy]] technologies are crucial for mitigating climate change impacts.\n",
    "    Changes in [[weather pattern|weather patterns]] and [[sea level|sea levels]] are key indicators.\"\"\",\n",
    "    \n",
    "    \"Internet\": \"\"\"The '''Internet''' is a global network that revolutionized [[communication]].\n",
    "    It operates using protocols like [[TCP/IP]] and enables various forms of [[e-commerce]].\n",
    "    [[World Wide Web|Web]] technologies have evolved from simple [[HTML]] to complex [[web application|web applications]].\n",
    "    Modern internet infrastructure relies heavily on [[cloud computing]] and [[data center|data centers]].\"\"\",\n",
    "    \n",
    "    \"Solar_System\": \"\"\"The '''Solar System''' consists of the [[Sun]] and celestial bodies bound by its gravity.\n",
    "    It includes eight [[planet|planets]], numerous [[moon|moons]], and countless [[asteroid|asteroids]].\n",
    "    The [[asteroid belt]] lies between [[Mars]] and [[Jupiter]].\n",
    "    [[Comet|Comets]] and [[meteor|meteors]] are other notable objects in our cosmic neighborhood.\"\"\",\n",
    "    \n",
    "    \"Human_Brain\": \"\"\"The '''human brain''' is the central [[organ]] of the [[nervous system]].\n",
    "    It consists of regions like the [[cerebral cortex]] and [[hippocampus]].\n",
    "    [[Neuron|Neurons]] communicate through [[synapse|synapses]] using [[neurotransmitter|neurotransmitters]].\n",
    "    Modern [[neuroimaging]] techniques like [[MRI]] help study brain structure and function.\"\"\",\n",
    "    \n",
    "    \"Artificial_Intelligence\": \"\"\"'''Artificial intelligence''' encompasses various approaches to creating intelligent systems.\n",
    "    Key subfields include [[machine learning]] and [[natural language processing]].\n",
    "    [[Computer vision]] systems can now perform complex visual tasks.\n",
    "    [[Expert system|Expert systems]] and [[robotics]] demonstrate practical AI applications.\n",
    "    Recent advances in [[deep learning]] have revolutionized the field.\"\"\",\n",
    "}\n",
    "\n",
    "# Dictionary of target pages\n",
    "target_pages = {\n",
    "    \"artificial intelligence\": \"\"\"Artificial intelligence (AI) is intelligence demonstrated by machines, \n",
    "    as opposed to natural intelligence displayed by animals including humans. AI systems can perform \n",
    "    tasks that typically require human intelligence.\"\"\",\n",
    "    \n",
    "    \"data\": \"\"\"Data are individual facts, statistics, or items of information, often numeric. In \n",
    "    computing, data represents information that can be processed, stored, or transmitted by computers.\"\"\",\n",
    "    \n",
    "    \"supervised learning\": \"\"\"Supervised learning is a machine learning approach where the model learns \n",
    "    from labeled training data to make predictions on new, unseen data. It's widely used in \n",
    "    classification and regression tasks.\"\"\",\n",
    "    \n",
    "    \"Earth\": \"\"\"Earth is the third planet from the Sun and the only astronomical object known to \n",
    "    harbor life. It's atmosphere and magnetic field protect life from harmful solar radiation.\"\"\",\n",
    "    \n",
    "    \"carbon dioxide\": \"\"\"Carbon dioxide (CO2) is a greenhouse gas that plays a vital role in Earth's \n",
    "    carbon cycle. Increased atmospheric CO2 from human activities is a major driver of climate change.\"\"\",\n",
    "    \n",
    "    \"TCP/IP\": \"\"\"TCP/IP (Transmission Control Protocol/Internet Protocol) is the foundational \n",
    "    communication protocol of the Internet. It specifies how data should be packetized, addressed, \n",
    "    transmitted, routed, and received.\"\"\",\n",
    "    \n",
    "    \"Sun\": \"\"\"The Sun is the star at the center of the Solar System. It is a nearly perfect sphere \n",
    "    of hot plasma, heated to incandescence by nuclear fusion reactions in its core.\"\"\",\n",
    "    \n",
    "    \"Mars\": \"\"\"Mars is the fourth planet from the Sun. Often called the Red Planet, it has a thin \n",
    "    atmosphere and features like valleys, deserts, and polar ice caps. It's a major target for \n",
    "    space exploration.\"\"\",\n",
    "    \n",
    "    \"cerebral cortex\": \"\"\"The cerebral cortex is the outer layer of neural tissue of the cerebrum \n",
    "    of the brain. It plays a key role in memory, attention, perception, awareness, thought, \n",
    "    language, and consciousness.\"\"\",\n",
    "    \n",
    "    \"machine learning\": \"\"\"Machine learning is a field of artificial intelligence that uses \n",
    "    statistical techniques to give computer systems the ability to 'learn' from data, without \n",
    "    being explicitly programmed.\"\"\"\n",
    "    # ... add more target pages as needed\n",
    "}\n",
    "\n",
    "def extract_citations(text: str) -> List[str]:\n",
    "    \"\"\"Extract all citations from a text and clean them.\"\"\"\n",
    "    citations = re.findall(r'\\[\\[(.*?)\\]\\]', text)\n",
    "    # Clean up citations (take first part if pipe character exists)\n",
    "    return [c.split('|')[0].lower() for c in citations]\n",
    "\n",
    "def create_training_batch(\n",
    "    model,\n",
    "    batch_size: int,\n",
    "    source_pages: Dict[str, str],\n",
    "    target_pages: Dict[str, str]\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Create a training batch by randomly sampling source pages and their citations.\n",
    "    \n",
    "    Args:\n",
    "        model: The citation matcher model\n",
    "        batch_size: Number of examples in the batch\n",
    "        source_pages: Dictionary of source page titles and their content\n",
    "        target_pages: Dictionary of target page titles and their content\n",
    "    \n",
    "    Returns:\n",
    "        source_contexts: List of prepared source contexts\n",
    "        target_contents: List of prepared target contents\n",
    "    \"\"\"\n",
    "    source_contexts = []\n",
    "    target_contents = []\n",
    "    \n",
    "    # Get random permutation of source page keys\n",
    "    source_keys = list(source_pages.keys())\n",
    "    random.shuffle(source_keys)\n",
    "    \n",
    "    # Try to fill the batch\n",
    "    attempts = 0\n",
    "    max_attempts = batch_size * 3  # Allow some extra attempts to fill the batch\n",
    "    \n",
    "    while len(source_contexts) < batch_size and attempts < max_attempts:\n",
    "        # Get next source page\n",
    "        source_key = source_keys[attempts % len(source_keys)]\n",
    "        source_text = source_pages[source_key]\n",
    "        \n",
    "        # Get all citations from this source page\n",
    "        citations = extract_citations(source_text)\n",
    "        \n",
    "        # Filter to citations that have matching target pages\n",
    "        valid_citations = [c for c in citations if c in target_pages]\n",
    "        \n",
    "        if valid_citations:\n",
    "            # Randomly select one citation\n",
    "            citation = random.choice(valid_citations)\n",
    "            \n",
    "            try:\n",
    "                # Prepare source context and target content\n",
    "                source_context = model.prepare_source_context(source_text, citation)\n",
    "                target_content = model.prepare_target_page(target_pages[citation])\n",
    "                \n",
    "                source_contexts.append(source_context)\n",
    "                target_contents.append(target_content)\n",
    "                \n",
    "            except ValueError as e:\n",
    "                print(f\"Error processing citation {citation} from {source_key}: {str(e)}\")\n",
    "        \n",
    "        attempts += 1\n",
    "    \n",
    "    if len(source_contexts) < batch_size:\n",
    "        print(f\"Warning: Could only create {len(source_contexts)} examples for requested batch size {batch_size}\")\n",
    "    \n",
    "    return source_contexts, target_contents\n",
    "\n",
    "def main():\n",
    "    # Initialize model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = AutoregressiveCitationMatcher(device=device)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    \n",
    "    # Training parameters\n",
    "    num_epochs = 3\n",
    "    batch_size = 4\n",
    "    steps_per_epoch = 10\n",
    "    \n",
    "    print(\"Starting training loop...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for step in range(steps_per_epoch):\n",
    "            # Create training batch\n",
    "            source_contexts, target_contents = create_training_batch(\n",
    "                model,\n",
    "                batch_size,\n",
    "                source_pages,\n",
    "                target_pages\n",
    "            )\n",
    "            \n",
    "            if not source_contexts or not target_contents:\n",
    "                print(\"Warning: Empty batch, skipping step\")\n",
    "                continue\n",
    "            \n",
    "            # Perform training step\n",
    "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                loss = model.train_step(\n",
    "                    source_contexts,\n",
    "                    target_contents,\n",
    "                    optimizer\n",
    "                )\n",
    "            \n",
    "            total_loss += loss\n",
    "            print(f\"Epoch {epoch + 1}, Step {step + 1}/{steps_per_epoch}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        avg_loss = total_loss / steps_per_epoch\n",
    "        print(f\"Epoch {epoch + 1} complete. Average loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Example of model usage after training\n",
    "    print(\"\\nTesting model with a sample prediction...\")\n",
    "    source_text = source_pages[\"Machine_Learning\"]\n",
    "    citation = \"artificial intelligence\"\n",
    "    \n",
    "    source_context = model.prepare_source_context(source_text, citation)\n",
    "    target_content = model.prepare_target_page(target_pages[citation])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            similarity = model([source_context], [target_content])\n",
    "    print(f\"Similarity score: {similarity[0][0].item():.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ce09ad-5500-4810-b8f9-dce292b3e8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
