{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e45919-7df5-473e-991b-8c2f6adfcedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 18:40:07,350 - INFO - Loading articles from JSONL file...\n",
      "2024-11-09 18:40:16,094 - INFO - Loaded 237381 articles\n",
      "2024-11-09 18:40:16,094 - INFO - Preparing training data...\n",
      "2024-11-09 18:40:17,153 - INFO - Preparing validation data...\n",
      "2024-11-09 18:40:17,704 - INFO - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing stats: {'skipped_no_cite': 1500, 'skipped_errors': 0, 'processed': 3410}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 18:41:12,140 - INFO - Starting training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing stats: {'skipped_no_cite': 371, 'skipped_errors': 0, 'processed': 795}\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█| 427/427 [04:06<00:00,  1.73it/s, loss=0.0490, avg_loss=1.3031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing validation embeddings: 100%|██████████| 50/50 [00:18<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing rankings for 795 samples...\n",
      "\n",
      "Validation Metrics:\n",
      "top_k_accuracy: {1: 0.1018867924528302, 3: 0.20251572327044026, 5: 0.2893081761006289, 10: 0.4088050314465409, 50: 0.7522012578616353}\n",
      "mrr: 0.1979\n",
      "median_rank: 18.0000\n",
      "mean_rank: 49.3698\n",
      "val_size: 795\n",
      "\n",
      "Epoch 1 Summary:\n",
      "Training Loss: 1.3031\n",
      "Validation Loss: 1.6764\n",
      "Best Top-1 Accuracy: 0.1019\n",
      "Mean Reciprocal Rank: 0.1979\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|▋| 307/427 [03:02<01:10,  1.70it/s, loss=0.5820, avg_loss=0.5371]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "from data_processing import (\n",
    "    ArticleContentProcessor,\n",
    "    CitationDataPreprocessor\n",
    ")\n",
    "from model_architecture import (\n",
    "    ModelConfig,\n",
    "    CitationMatcher,\n",
    "    CitationDataset,\n",
    "    create_dataloader\n",
    ")\n",
    "from training_module import (\n",
    "    TrainingConfig,\n",
    "    train_model\n",
    ")\n",
    "\n",
    "def setup_logging(output_dir: Path) -> None:\n",
    "    \"\"\"Configure logging for the training process.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(output_dir / 'training.log'),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def setup_environment() -> None:\n",
    "    \"\"\"Configure training environment.\"\"\"\n",
    "    # Set environment variables\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "    \n",
    "    # Set random seeds for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "\n",
    "def create_output_directory() -> Path:\n",
    "    \"\"\"Create and return output directory for this training run.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = Path(f\"training_runs/run_{timestamp}\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return output_dir\n",
    "\n",
    "def load_and_prepare_data(\n",
    "    jsonl_path: str,\n",
    "    train_sample_size: int,\n",
    "    val_sample_size: int\n",
    ") -> tuple:\n",
    "    \"\"\"Load and prepare training and validation data.\"\"\"\n",
    "    logging.info(\"Loading articles from JSONL file...\")\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        articles_dict = {}\n",
    "        for line in f:\n",
    "            article = json.loads(line)\n",
    "            content = ArticleContentProcessor.clean_wiki_content(article['text'])\n",
    "            if content:\n",
    "                articles_dict[article['title'].lower()] = content\n",
    "    \n",
    "    logging.info(f\"Loaded {len(articles_dict)} articles\")\n",
    "    \n",
    "    # Prepare citation data\n",
    "    preprocessor = CitationDataPreprocessor(articles_dict)\n",
    "    \n",
    "    logging.info(\"Preparing training data...\")\n",
    "    train_sources, train_targets = preprocessor.create_citation_pairs(\n",
    "        sample_size=train_sample_size,\n",
    "        cite_samples_per_article=1\n",
    "    )\n",
    "    \n",
    "    logging.info(\"Preparing validation data...\")\n",
    "    val_sources, val_targets = preprocessor.create_citation_pairs(\n",
    "        sample_size=val_sample_size,\n",
    "        cite_samples_per_article=10\n",
    "    )\n",
    "    \n",
    "    return train_sources, train_targets, val_sources, val_targets\n",
    "\n",
    "def main():\n",
    "    # Setup\n",
    "    output_dir = create_output_directory()\n",
    "    setup_logging(output_dir)\n",
    "    setup_environment()\n",
    "    \n",
    "    # Configuration\n",
    "    model_config = ModelConfig(\n",
    "        model_name=\"bert-base-uncased\",\n",
    "        max_length=512,\n",
    "        cite_token=\"<CITE>\",\n",
    "        ref_token=\"<REF>\",\n",
    "        temperature=0.07\n",
    "    )\n",
    "    \n",
    "    training_config = TrainingConfig(\n",
    "        batch_size=32,\n",
    "        num_epochs=10,\n",
    "        learning_rate=1.5e-4,\n",
    "        temperature=0.1,\n",
    "        num_workers=4,\n",
    "        gradient_clip_value=1.0,\n",
    "        scheduler_patience=2,\n",
    "        scheduler_factor=0.5,\n",
    "        eval_k_values=[1, 3, 5, 10, 50]\n",
    "    )\n",
    "    \n",
    "    # Data preparation\n",
    "    train_sources, train_targets, val_sources, val_targets = load_and_prepare_data(\n",
    "        jsonl_path='./wiki_articles.jsonl',\n",
    "        train_sample_size=20000,\n",
    "        val_sample_size=1000\n",
    "    )\n",
    "    \n",
    "    # Model initialization\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "    \n",
    "    model = CitationMatcher(model_config).to(device)\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = CitationDataset(\n",
    "        sources=train_sources,\n",
    "        targets=train_targets,\n",
    "        tokenizer=model.tokenizer,\n",
    "        config=model_config,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = CitationDataset(\n",
    "        sources=val_sources,\n",
    "        targets=val_targets,\n",
    "        tokenizer=model.tokenizer,\n",
    "        config=model_config,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    train_loader = create_dataloader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=training_config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=training_config.num_workers\n",
    "    )\n",
    "    \n",
    "    val_loader = create_dataloader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=training_config.batch_size * 2,\n",
    "        shuffle=False,\n",
    "        num_workers=training_config.num_workers\n",
    "    )\n",
    "    \n",
    "    # Training\n",
    "    logging.info(\"Starting training...\")\n",
    "    metrics_history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        config=training_config,\n",
    "        save_dir=output_dir / 'checkpoints',\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Save training history\n",
    "    torch.save(\n",
    "        {\n",
    "            'metrics_history': [metric.__dict__ for metric in metrics_history],\n",
    "            'model_config': model_config.__dict__,\n",
    "            'training_config': training_config.__dict__\n",
    "        },\n",
    "        output_dir / 'training_history.pt'\n",
    "    )\n",
    "    \n",
    "    logging.info(f\"Training completed. Results saved to {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        logging.exception(\"An error occurred during training:\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ba1cc-d1d3-4cf5-9fbb-e82f0e4186a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb302bc-5802-4f5d-959c-4bdf4c9acdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f27a2-64ab-4277-ad92-4dc3b610b132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
