# Fast training configuration for testing
global_batch_size: 32
micro_batch_size: 4
stream_chunk_size: 64
tau: 0.07
lr: 1e-3
num_epochs: 2
max_length: 128
output_dim: 512
drop_last: true

# LoRA configuration
lora:
  enabled: true
  r: 8
  lora_alpha: 16
  lora_dropout: 0.05